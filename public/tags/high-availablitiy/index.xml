<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>high-availablitiy | Alexander Salimonov</title>
    <link>/tags/high-availablitiy/</link>
      <atom:link href="/tags/high-availablitiy/index.xml" rel="self" type="application/rss+xml" />
    <description>high-availablitiy</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Alexander Salimonov · ©  2019</copyright><lastBuildDate>Mon, 14 Jan 2019 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar_salimonov_small.jpeg</url>
      <title>high-availablitiy</title>
      <link>/tags/high-availablitiy/</link>
    </image>
    
    <item>
      <title>Высокая доступность: концепции, общие практики построения и сопровождения</title>
      <link>/post/2019/03-distsys/</link>
      <pubDate>Mon, 14 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019/03-distsys/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;
&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul class=&#34;sectlevel1&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Концепции&#34;&gt;Концепции&lt;/a&gt;
&lt;ul class=&#34;sectlevel2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Основы&#34;&gt;Основы&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_cap_теорема&#34;&gt;CAP теорема&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Модели_консистентности&#34;&gt;Модели консистентности&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_acid&#34;&gt;ACID&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_base&#34;&gt;BASE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_pacelc&#34;&gt;PACELC&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_conways_law&#34;&gt;Conway&amp;#8217;s law&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Избыточность&#34;&gt;Избыточность&lt;/a&gt;
&lt;ul class=&#34;sectlevel2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Толерантность_к_отказам_fault_tolerance&#34;&gt;Толерантность к отказам (fault tolerance)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_active_active&#34;&gt;Active-Active&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_multi_master&#34;&gt;Multi-Master&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_master_replica&#34;&gt;Master-Replica&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Аварийное_переключение_failover_стратегии_и_практики&#34;&gt;Аварийное переключение (failover), стратегии и практики&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Управление_отказами&#34;&gt;Управление отказами&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_sla_slo_sli&#34;&gt;SLA, SLO, SLI&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Организационные_подходы_для_построения_систем_высокой_доступности&#34;&gt;Организационные подходы для построения систем высокой доступности&lt;/a&gt;
&lt;ul class=&#34;sectlevel2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Не_экономить_на_самом_дешевом_железе&#34;&gt;Не экономить на самом дешевом железе&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Согласованность&#34;&gt;Согласованность&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Ответственность&#34;&gt;Ответственность&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Устранение_единых_точек_отказа_single_point_of_failure_spof&#34;&gt;Устранение единых точек отказа (Single Point of Failure (SPOF))&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Консолидация_серверов&#34;&gt;Консолидация серверов&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Автоматизация_и_оптимизиация&#34;&gt;Автоматизация и оптимизиация&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Типовые_конфигурации_и_общие_репозитории&#34;&gt;Типовые конфигурации и общие репозитории&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Мониторинг_и_оповещение&#34;&gt;Мониторинг и оповещение&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Измерение_производительности&#34;&gt;Измерение производительности&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Обучение_и_тренинги_персонала&#34;&gt;Обучение и тренинги персонала&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Раздельные_контуры&#34;&gt;Раздельные контуры&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Заключение&#34;&gt;Заключение&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Ссылки&#34;&gt;Ссылки&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Концепции&#34;&gt;Концепции&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В прошлых статьях рассмотрели причины сбоев, типичный таймлайн сбоев, какие фазы там есть и какие действия обычно требуются, чтобы вернуть систему в стабильное рабочее состояние. Настало время погружаться в теорию HA глубже, но попытаться не распыляться на конкретные компоненты и решения, чтобы сохранить универсальность и иметь возможность применять их безотносительно частных случаев и реализаций.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Так, проектируя HA систему, прежде всего преследуют цель построить систему, которая бы за минимальные деньги держала определенную нагрузку и лишний раз не беспокоила (что в принципе тоже деньги). Соответственно, система должна быть:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Надежной:&lt;/strong&gt; минимальный потенциал для сбоев.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Избыточной:&lt;/strong&gt; использовать имеющиеся ресурсы, чтобы продолжать работать даже после сбоя без внешнего вмешательства.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Простой в управлении:&lt;/strong&gt; все рабочие процессы, связанные с ней, понятны, зоны ответственности определены, на оперативные действия тратится минимум времени и усилий.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И уже тут начинаются противоречия. Чем меньше компонентов в системе и их связанность - тем она надежней, при увеличении избыточности увеличивается и связанность, а количество сбоев в системе растет. Почему так? Рассмотрим в последующей статье - &#34;Высокая доступность: надёжность компонентов и систем&#34;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Управление распределенной системой сопряжено с её же сложностью, которую хотя бы отчасти удаётся скрыть под абстракциями систем управления конфигурациями, возможностями управлять группами развернутых сервисов, оркестрацией кластеров, формированием виртуальных сетей и даже клаудов.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В предыдущей статье был приведён пример расчёта влияния увеличения доступности на выручку, получаемую организацией. В подходах обеспечения HA для системы, либо её части, следует поступать аналогичным образом, то есть доставлять доступность как новую функцию с некоторой ценностью для бизнеса, с возможностью посчитать её ROI. Тем самым доступность системы будет находиться в соответствии с потребностями бизнеса, его планами и возможностями. А обоснование работ, критерии достижимости и средства, будут понятны и для владельцев продукта, и для исполнителей.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Упрощенная схема влияния доступности на выручку:&lt;br&gt;
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/impact_of_availability.png&#34; alt=&#34;Влияние доступности на выручку и затраты&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;При такой простой мотивации поступают так же просто:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;анализируется текущий дизайн системы на возможные отказы;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;составляется список сценариев отказа;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;для каждого сценария указывается вероятность отказа и урон, им созданный;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;важные сценарии для бизнеса фиксируются в требованиях;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;проектирование решений по преодолению этих сценариев, оценивается стоимость реализации;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;ревью решений, проверка гипотез по преодолению отказов;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;реализация.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Потребность в высокой доступности может быть вызвана не только увеличением прибыли и уменьшения рисков, но и для соответствия определенным отраслевым и государственным стандартам и регламентам.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Основы&#34;&gt;Основы&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Отказоустойчивые системы, а значит системы с некоторой избыточностью, также являются подгруппой распределенных систем. При работе с ними инженеры иногда забывают о фундаментальных ограничениях или по привычке используют упрощенные модели, L. Peter Deutsh сформировал список из таких &lt;strong&gt;заблуждений&lt;/strong&gt; в распределенных вычислениях:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Сеть надёжна.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Задержка (latency) сети равна нулю.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Пропускная способность бесконечна.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Сеть безопасна.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Топология не меняется.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Только один администратор.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Затраты времени на передачу равны нулю.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Сеть гомогенная.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Дополнение и объяснение этих заблуждений будет выходить за рамки данной статьи, но Вы сможете найти больше информации в публикации &lt;a href=&#34;http://www.rgoarchitects.com/Files/fallacies.pdf&#34;&gt;Fallacies of Distributed Computing: Explained&lt;/a&gt; от архитектора Arnon Rotem-Gal-Oz.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_cap_теорема&#34;&gt;CAP теорема&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В этих заблуждениях упомянули, что задержка по сети не равна нулю, что пропускная способность не бесконечна, что сама сеть не надёжна. В следствии того, что информация не может распространяться по разным узлам сети мгновенно и в любом объеме, спровоцировано появление большого количества моделей управления данными в распределенных системах, а на основе них появилась CAP теорема &lt;a href=&#34;#cap&#34;&gt;[cap]&lt;/a&gt;. Поверхностные детали теоремы рассматривать не будем, так как они интуитивно простые, прочтения статьи с Wikipedia достаточно. Сложность как обычно в деталях, а именно &lt;strong&gt;моделях консистентности&lt;/strong&gt;, которые будут влиять на такие характеристики системы как: латентность, пропускная способность, величину RPO, способ решения проблем конкурентности.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Модели_консистентности&#34;&gt;Модели консистентности&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Существует довольно большое множество моделей консистентности, которые описывают различные подходы при работе с данными в распределенной системе и естественно с больше, чем одним агентом, которые с ними работают. Так как статья посвящена высокодоступным системам, то мы подразумеваем, что клиенты получают доступ к сервису без ожиданий и попыток синхронизироваться друг с другом, то есть система работоспособна даже тогда, когда доступен остался лишь один узел. Это называется &lt;code&gt;wait-free&lt;/code&gt;-атрибут распределенной системы. В следствии наличия wait-free атрибута, приходится раскрывать сам факт конкурентности доступа к данным в такой системе. Так как бизнес диктует свои потребности с некоторой областью возможностей, то при проектировании системы и мы можем выбирать, в каких случаях и как организовать проведение транзакций. Транзакций не в терминах СУБД, а в терминах предметной области, что важно.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Так выбираем между абсолютно строгим подходом доступа к данным и состоянием постоянной неконсистентности на узлах. Более формально: самый строгий способ достижения консистентности - использовать лишь один объект с данными и организовывать последовательный доступ к нему, если клиентов больше одного, то ни о каком wait-free там речи быть не может. Ослаблять требования этого способа можем через смягчающий критерий - раскрытие деталей конкурентной работы с данными, тем самым выстраивая правила (протокол) работы с ними, не допуская случаи появления неконсистентности в данных. Под протоколом подразумевается нахождение консенсуса для линеаризации проводимых транзакций.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ниже представлена решетка моделей консистентности от самого слабого критерия до сильного. Граф разделён CAP границей, всё что ниже неё может использоваться в wait-free системах, всё что выше - нет.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Решётка моделей консистентности&lt;a href=&#34;#ds1e&#34;&gt;[ds1e]&lt;/a&gt;:
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/consistancy_lattice.png&#34; alt=&#34;Решетка консистентности&#34;&gt;&lt;/span&gt;
Как видно из изображения, в wait-free системе могу быть реализованы: update consistency модель, eventual concistency, pipelined consistency.&lt;br&gt;
Отдельно хочется отметить serilizability, многие инженеры ошибочно считают, что она даст возможность забыть о проблеме консистентности проведения транзакций в распределённой системе. Она строже event consistency, но всё же не исключает проблем при разделении кластера (&lt;a href=&#34;https://en.wikipedia.org/wiki/Split-brain_(computing)&#34;&gt;split brain&lt;/a&gt;), так как гарантирует проведение изолированных серий транзакций на локальных данных, а синхронизацию через shared object и арбитраж. Когда отделившийся узел возвращается в кластер, он будет вынужден вернуться к состоянию в момент сплита, либо потребует операцию по слиянию данных. Такая модель позволяет реализовать хорошие показатели производительности и предоставляет отличный контроль данных. Именно поэтому получила столь широкое распространение и для работы с важными данными (мед. записи, банковские транзакции), но как всегда есть нюансы.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Сверху находятся модели с жесткими критериями последовательности транзакций и линеаризацией, получается не wait-free система, но данные однозначно останутся консистентными в любой момент времени. Для более более подробного знакомства с этими моделями рекомендую заглянуть в &lt;a href=&#34;#ds1e&#34;&gt;[ds1e]&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_acid&#34;&gt;ACID&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Большинство с ACID должны быть знакомы в общих чертах и даже в трактовках. Если нет - есть &lt;a href=&#34;https://en.wikipedia.org/wiki/ACID_(computer_science)&#34;&gt;wiki: ACID_(computer_science)&lt;/a&gt;. Продолжаем тему применимости принципов и моделей в построении HA систем. Ниже граф уровни изоляции транзакций (AC&lt;strong&gt;I&lt;/strong&gt;D) на основе CAP моделей, источник &lt;a href=&#34;#hat&#34;&gt;[hat]&lt;/a&gt;  (нарисовал &lt;a href=&#34;https://twitter.com/0x0FFF/&#34;&gt;Alexey Grischenko&lt;/a&gt;):
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/cap_map.jpeg&#34; alt=&#34;CAP map&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Что это значит:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;граф - корень (Strong-1SR) - наивысший уровень &#34;изоляции&#34; транзакций (все транзакции последовательны), чем дальше от корня, тем ниже уровень изоляции транзакции, тем меньше нужно ресурсов на её проведение в распределённом приложении&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;красное - модель невозможно использовать в HA системе&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;зелёное - используется&lt;br&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;синее - используется для тех случаев, когда клиент работает лишь с одним узлом, либо сам может выполнять роль сервера.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Практическое использование. В большинстве классических РСУБД по умолчанию используется serializable модель, иногда и как наиболее строгая, пример PostgreSQL &lt;a href=&#34;#pgsql-tr&#34;&gt;[pgsql-tr]&lt;/a&gt;. Microsoft SQL Server &lt;a href=&#34;#mssql-si&#34;&gt;[mssql-si]&lt;/a&gt;  и Oracle &lt;a href=&#34;#oracle-si&#34;&gt;[oracle-si]&lt;/a&gt; позволяют повысить изоляцию до snapshot isolation.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В принципе, когда говорят про &lt;strong&gt;C&lt;/strong&gt;AP и AC&lt;strong&gt;I&lt;/strong&gt;D, зачастую подразумевают не serializable, а linearizable консистентность. Нюанс тут в том, что большинство РСУБД используют serializable или snapshot уровни изоляции с &lt;a href=&#34;https://en.wikipedia.org/wiki/Multiversion_concurrency_control&#34;&gt;Multivesion concurrency control (MVCC)&lt;/a&gt;, но не способны реализовать линеаризуемость транзакций, так как это сильно снизит скорость конкурентного доступа к данным. В этом и есть неочевидный и мало кому знакомый нюанс использования этих терминов.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Те, кто уже хорошо знаком с ACID, могут обратить внимание, что сериализуемые транзакции, являющиеся &#34;эталоном&#34; для достижения целостности и истинности данных в принципе для большой распределенной системы, не подходят из-за жестких ограничений. При большом количестве узлов требует и больших затрат ресурсов, и времени, нет толерантности к разделению(CA&lt;strong&gt;P&lt;/strong&gt;). Это и вызвало появление AP NoSQL систем таких как Amazon Dynamo, Cassandra.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Из-за вот таких неочевидных нюансов, невозможности отнести все системы к классу CA, AP, CP, потребности более точно и кратко описать системы использующие не serializable модель и появились &lt;a href=&#34;#_base&#34;&gt;BASE&lt;/a&gt; и &lt;a href=&#34;#_pacelc&#34;&gt;PACELC&lt;/a&gt; аббревиатуры.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_base&#34;&gt;BASE&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Обязано появлением систем на основе eventual consistency, для которых приемлемо находиться в неконсистетном состоянии какое-то время и отдавать клиенту неконсистентные данные, тем самым сохраняя доступность.
BASE - &lt;strong&gt;B&lt;/strong&gt;asically &lt;strong&gt;A&lt;/strong&gt;vailable, &lt;strong&gt;S&lt;/strong&gt;oft state, &lt;strong&gt;E&lt;/strong&gt;ventual consistency. По графу моделей консистентности видно, что они не такие жесткие, как системы на serializable модели.
Пример BASE-баз данных: CouchDB, Amazon SimpleDB, Amazon Dynamo, Riak.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_pacelc&#34;&gt;PACELC&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ещё одна post-CAP теорема, а фактически её расширение. Созданное, чтобы в общую модель добавить современные NoSQL решения. Была предложена в работе &#34;Consistency Tradeoffs in Modern Distributed Database System Design&#34; &lt;a href=&#34;#abadi&#34;&gt;[abadi]&lt;/a&gt;. Трактовка из оригинала:&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;pacelsabadi&#34; class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;A more complete portrayal of the space of potential consistency tradeoffs for DDBSs can be achieved by rewriting CAP as PACELC (pronounced “pass-elk”): if there is a partition (&lt;strong&gt;P&lt;/strong&gt;), how does the system trade off availability and consistency (&lt;strong&gt;A&lt;/strong&gt; and &lt;strong&gt;C&lt;/strong&gt;); else (&lt;strong&gt;E&lt;/strong&gt;), when the system is running normally in the absence of partitions, how does the system
trade off latency (&lt;strong&gt;L&lt;/strong&gt;) and consistency (&lt;strong&gt;C&lt;/strong&gt;)?&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;attribution&#34;&gt;
&amp;#8212; Daniel J. Abadi
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Теперь в рамках одной теоремы можно более точно указать &#34;классы&#34; хранилищ и описать требования к ним. Классические ACID системы - PC/EС. Сохраняют целостность кластера (P), консистетность (С), но вынуждены жертвовать доступностью и задержками ради (E) консистентности (С).
Современные NoSQL, в лице MongoDB, Amazon Dynamo, Cassandra, Aerospike являются PA/EL: уcтойчивы к сплитам (P), сохраняют доступность (A), но жертвуют консистентностью ради (E) низких задержек (L).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;dlist&#34;&gt;
&lt;dl&gt;
&lt;dt class=&#34;hdlist1&#34;&gt;NOTE&lt;/dt&gt;
&lt;dd&gt;
&lt;p&gt;Выше приведены модели, используемые по умолчанию. Большинство современных СУБД поддерживают конфигурирование уровней коснистентности, которые могут зависеть от настроек сервера, базы, сессии. Обращайте на это внимание при работе с ними, а тем более при выборе СУБД.&lt;/p&gt;
&lt;/dd&gt;
&lt;/dl&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Для более детальной информации, рекомендую всё же ознакомиться c &lt;a href=&#34;#abadi&#34;&gt;[abadi]&lt;/a&gt; и заглянуть в &lt;a href=&#34;https://en.wikipedia.org/wiki/PACELC_theorem&#34;&gt;wikipedia&lt;/a&gt;, где приводятся классы наиболее популярных СУБД.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_conways_law&#34;&gt;Conway&amp;#8217;s law&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Отдельно хочется упомянуть Conway&amp;#8217;s Law.&lt;/p&gt;
&lt;/div&gt;
&lt;div id=&#34;conwayslaw&#34; class=&#34;quoteblock&#34;&gt;
&lt;blockquote&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;organizations which design systems &amp;#8230;&amp;#8203; are constrained to produce designs which are copies of the communication structures of these organizations.&lt;/p&gt;
&lt;/div&gt;
&lt;/blockquote&gt;
&lt;div class=&#34;attribution&#34;&gt;
&amp;#8212; M. Conway
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Строя распределённую систему, формируйте команды под задачи, а не наоборот. Иначе система будет иметь такие же проблемы, что и &lt;a href=&#34;https://twitter.com/shanselman/status/790285272021803008&#34;&gt;здесь&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Существует множество других законов и следствий, которые прямым или косвенным образом связаны с распределенными и высокодоступными системами, но вместить их может, пожалуй, целая энциклопедия (например - &lt;a href=&#34;https://www.springer.com/gp/book/9780387097657&#34;&gt;Encyclopedia of Parallel Computing&lt;/a&gt;), так что здесь ограничимся лишь самыми базовыми.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Избыточность&#34;&gt;Избыточность&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Как ранее было описано, избыточность в системе позволяет продолжить работу после сбоя и даже без потери данных. Избыточность в компонентах системы может быть на разных уровнях, всё зависит от того, для какого сценария сбоя эти избыточные компоненты предназначены.
Примеры создания избыточности:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;зеркалирование дисков - RAID &lt;a href=&#34;#wiki_raid&#34;&gt;[wiki_raid]&lt;/a&gt; или &lt;strong&gt;Redundant&lt;/strong&gt; Arrays of Independet Disks&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;резервные блоки питания серверов&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;дополнительные сетевые интерфейсы, коммутаторы&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;резервные линии электроснабжения, питание серверов через источники бесперебойного питания&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;избыточность в кластере сервисов, обычно он называется высокодоступным кластером или HA cluster.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Если блок компонентов содержит в себе избыточность и может без внешнего вмешательства переключаться на избыточный (резервный) элемент, который и возьмет на себя нагрузку. Такой компонент называется устойчивым к сбоям (fault-tolerant). Далее рассмотрим стратегии и прочие нюансы при переключении на избыточные элементы системы после сбоя, а также конфигурации отказоустойчивых кластеров.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Толерантность_к_отказам_fault_tolerance&#34;&gt;Толерантность к отказам (fault tolerance)&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Как ранее уже упоминалось, не все отказы можно обработать, поэтому фокусируются лишь на некоторых, ориентируясь на потребности. Ниже четыре самых главных подхода обработки отказа:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Masking tolerance - обработка отказа без существенных изменений клиента, агента или связанного компонента, используется в критически важных системах.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Nonmasking tolerance - сбой может временно повлиять на связанный компонент, но без эскалации сбоя выше него, как правило это видно по увеличению таймингов.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Fail-Safe - обработка отказа с прерыванием операции в безопасном для остальных состоянии. Самоликвидация ракет, мин, плавное торможение самоуправляемого автомобиля и есть fail-safe.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Graceful degradation - после сбоя система не может скрыть последствия сбоя, не может восстановиться, функционирует с ограничениями, сниженной производительностью. Пример: использование резервного канала с меньшей пропускной способностью и более высокими задержками, временное нарушение консистентности, которое можно считать приемлемым, недоступность части сервисов.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Если последствия отказа нельзя скрыть от клиента или зависимых компонентов (невозможно, слишком дорого, не критично), то нужно его хотя бы локализовать, переведя и функционирование зависимого компонента в ограниченный режим. Такая локализация поможет определить сбой в системе более точно, быстро, проще будет обработать.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ниже рассмотрим самые популярные схемы организации избыточности кластеров для обработки отказов.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_active_active&#34;&gt;Active-Active&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Один из самых популярных вариантов организации высокодоступных кластеров при построении Web-сервисов. Все узлы в активном использовании, балансировщик раскидывает трафик в зависимости от его политики (random, round robin, etc.). В случае, если один из узлов перестал отвечать, балансировщик сам может перекинуть коннект на другой узел, тем самым избежав потери данных и с нулевым даунтаймом.
Плюсы:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;уменьшение даунтайма, так как фактический узел невидим для клиента&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;эффективное использование оборудования, реализация полной его ёмкости&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;легко наращивать нагрузку&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;тестирование аварийного переключения за балансировщиком менее рискованное&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Минусы:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;организация такой архитектуры сопряжена с определенными трудностями или вообще невозможна в случае хранения состояния (сессии) на стороне сервера. Не всегда можно привязать юзеров к конкретному серверу за балансировщиком, failover также будет сопряжен с определенными проблемами.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;возможны коллизии данных без роутинга клиентов на определенные узлы&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;следует крайне аккуратно рассчитывать запас по производительности в случае выхода из строя одного из узлов, производительность может упасть не линейно и вызвать отказ и второго узла.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Примеры: кластера WEB, REST серверов.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_multi_master&#34;&gt;Multi-Master&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Сходный принцип с Activ-Active, за тем исключением, что балансировщик обычно не используется, обычно клиент уже знает несколько адресов Master узлов, к которым и пробует подключаться. В случае невозможности подсоединиться к первому, пробует следующий адрес и т.д.
Встречается в двух основных случаях: процессинг большого количества данных (батчи, стримы), отказоустойчивые БД.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В случае процессинга мастер-узлы сами выполняют лишь координационную функцию, обмениваясь между собой метаданными и занимаясь скедулингом (Spark, Flink)&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В базах данных: Cassandra, MySQL с Multi-Master, Aerospike, MSSQL c P2P transaction replication.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_cold_standby&#34;&gt;Cold Standby&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Один активный компонент предоставляет нужные для системы функции. Когда случается его отказ, cold standby компонент переходит в режим hot и замещает предыдущий. В системе может быть более чем два компонента, тем самым повышая её живучесть. Её плюс в том, что в такой системе деградация очевидна и скорость отказов (failure reate) константна, что упрощает оценку и прогнозирование. Практически был вытеснен, остался в legacy c монолитами.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_hot_standby&#34;&gt;Hot Standby&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В этом случае standby компонент, который защищает основной, также включен. Данные на standby реплицируются с секундными интервалами. В случае отказа основного компонента, происходит переключение (failover) на второй, в случае успешного переключения downtime стремится или равен нулю. Но есть следующие нюансы:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Из-за того, что они находятся под разной нагрузкой у них могут быть и разные скорости отказа.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Подразумевается, что механизм переключения абсолютно надёжен, если нет - система также подвергнется отказу&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;В случае отказа standby компонента система не затронута.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В качестве примера такой архитектуры можно привести: PostgreSQL, MySQL, MSSQL.
HDFS где инстансы используются NameNode в таком режиме. Также практикуется развертывание Cassandra кластеров в multizone-Region в AWS.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_master_replica&#34;&gt;Master-Replica&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Вариация Hot Standby. Все узлы кластера проверяют друг друга на доступность по heartbeat. В случае обнаружения недоступности master узла инициализируют выбор нового и проводят failover. Узлы-реплики могут использоваться для чтения.
Пример: MongoDB (replica set), Redis, MSSQL, MySQL, PostgreSQL, RabbitMQ, Kafka (но есть нюансы).&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_2n_избыточность_2n_redundancy&#34;&gt;2N избыточность (2N Redundancy)&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Схема, напоминающая Hot Standby. Все избыточные юниты проверяют доступность друг друга. При обнаружении, что активный (эксплуатируемый) юнит недоступен, инициализируются аварийное переключение (failover). Ранее была распространена в телекоме, как схема увеличения надёжности через использование аналогичного железа, но различного ПО, выполняющего аналогичные функции, чтобы избежать отказа всех узлов в критически важной системе с одной и той же ошибкой в ПО. Сейчас подобная схема используется преимущественно в инфраструктуре датацентров для управление питанием.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_Трёх_компонентное_большинство_с_голосованием_triplex_duplex&#34;&gt;Трёх-компонентное большинство с голосованием (Triplex-Duplex)&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В эксплуатации находятся три компонента, вывод от всех трёх компонентов сравнивается между собой, если один из компонентов выдаёт отличное от большинства значение, то он больше не может рассматриваться как достоверный и выводится из эксплуатации. Компоненты не подлежат ремонту во время эксплуатации, только замена. Схема используется в критически важных системах: авионика, медицинские системы, системы жизнеобеспечения, индустриальные системы повышенной надёжности.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Аварийное_переключение_failover_стратегии_и_практики&#34;&gt;Аварийное переключение (failover), стратегии и практики&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Для аппаратных компонентов failover обрабатывается в драйверах системы, которые предоставляет вендор вместе с железом. Нормальная обработка такого failover не вызывает прекращение работы оборудования и не вызывает перезагрузку ОС.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Если сбой происходит в кластере, миграция между сервисами внутри него должна удовлетворять следующим критериям:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Прозрачность.&lt;/strong&gt; Аварийное переключение после восстановления не должно мешать работе клиентов. Так сбой у master/active узла в HA кластере должен повлечь переброс трафика на резервный standby узел (который становится active) и установления соединений от клиентов к этому серверу, после чего возобновляется их нормальная работа. Опционально возможно выполнение повторных процедур аутентификации.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Время переключения.&lt;/strong&gt; В идеале не должно приводить к длительной остановке зависимого клиента. Так например в HA &lt;code&gt;replica set&lt;/code&gt; кластерах c небольшим количеством узлов, secondary узлы через определенные промежутки времени опрашивают primary, если он недоступен, то выбирают (election) новый primary узел, который принимает на себя клиентов или управляет взаимодействием с ними. Период времени (heartbeat rate) между опросами обычно настраиваемый и не больше двух минут. Таким образом, клиент, потеряв соединение с primary (по его таймауту), пытается соединиться с каким-нибудь другим узлом из кластера, который можно было бы идентифицировать как новый primary. В этом случае, согласованно и рационально настроенные таймаут соединения, hearbeat rate и на клиенте имеются retry политики и backpessure подход (о них позже), то переключение на новый primary сервер должно занять максимум несколько минут и не привести к потере данных для клиента.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Автоматизация.&lt;/strong&gt; Переключение на избыточный узел желательно осуществлять в автоматическом режиме, чтобы способствовать уменьшению MTTR. Если внутри кластера сервера имеют разные статусы, то механизм выбора главного сервера также должен запускаться автоматически.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Гарантированный доступ к предоставляемому сервису.&lt;/strong&gt; После аварийного переключения клиент должен иметь доступ к тем же самым данным (но есть нюансы в виде консистентности данных на различных узлах) и тем же самым сервисам, которые предоставлялись прошлым сервером в этом кластере.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Управление_отказами&#34;&gt;Управление отказами&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Таймлайны отказов рассматривали ранее, сейчас вкратце:
Вкратце:
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/fault_management.jpg&#34; alt=&#34;242&#34; width=&#34;540&#34; height=&#34;Fault management&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Современные Agile подходы с короткими циклами релизов, CI/CD практики и прочий Ops-инструментарий очень сильно упростили работу с отказами, позволяя эксплуатировать большие системы существенно меньшим количеством людей.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Чек-лист того, чтобы упросить детекцию, диагностику отказов, а также оценку эффекта от их возникновения:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;healt-check сервисов&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;сбор логов&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;сбор метрик&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;определение пороговых значений (thresholds) для выше обозначенных метрик&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;оповещения для администраторов, сотрудников поддержки занятых в эксплуатации, инцидент- трекинг сервис (PageDuty, VictorOps)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;использование фреймворков для трейсинга&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;автоматизация обработки отказов&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;организация дежурств, уровней саппорта, политик экскалаций&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;журнал postmortem с отчётами о развитии крупных отказов, описание поиска решения, что сделано, чтобы предотвратить в будущем. Не забывать им делиться с другими командами.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_sla_slo_sli&#34;&gt;SLA, SLO, SLI&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Есть несколько подходов по работе с документами связанными с доступностью системы. Различия в них не концептуальные, но связанные с бизнес-моделью организации и внутренними процессами.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;hdlist&#34;&gt;
&lt;table&gt;
&lt;tr&gt;
&lt;td class=&#34;hdlist1&#34;&gt;
Service Level Agreement (SLA)
&lt;/td&gt;
&lt;td class=&#34;hdlist2&#34;&gt;
&lt;p&gt;договоренность об уровне сервиса&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;hdlist1&#34;&gt;
Service Level Objectives (SLO)
&lt;/td&gt;
&lt;td class=&#34;hdlist2&#34;&gt;
&lt;p&gt;цели по предоставлению уровня сервиса (внутренние требования (документы)), является более строгим набором требований чем SLA, так как нарушение последнего может привести к явным финансовым и репетиционным потерям.&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;hdlist1&#34;&gt;
Service Level Indicators (SLI)
&lt;/td&gt;
&lt;td class=&#34;hdlist2&#34;&gt;
&lt;p&gt;метрики доступности системы&lt;/p&gt;
&lt;/td&gt;
&lt;/tr&gt;
&lt;/table&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;SLA&lt;/strong&gt; - соглашение между лицом, сервис представляющим и лицом, являющимся его клиентом. Может быть оформлено в виде документа, где явно прописаны обязанности первого лица, условия, исключения если такие есть. Чаще всего там прописывается: процент доступности, MTTR, график обслуживания когда сервис может быть недоступен либо функционировать в ограниченном режиме, производительность сервиса, размеры штрафа в случае несоблюдения указанных ранее характеристик и свойств. Рекомендуется в SLA указывать те характеристики сервиса, которые влияют непосредственно на выручку, то есть фокусироваться на наиболее приоритетных и для клиентов, и для инженеров.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;SLO&lt;/strong&gt; - внутренний документ, описывающий цели по доступности. В нём содержатся те же самые характеристики и свойства системы, что и в SLA, но с более строгими значениями, что бы иметь запас по надёжности между целью и договорённостями с клиентами. Источник информации по пороговым значениями (thresholds) для систем мониторинга и оповещения.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;strong&gt;SLI&lt;/strong&gt; - текущие измеряемые показатели сервиса. Там могут быть типичные RPS, QPS, latency, пропускная способность, так и собственные замеры доступности. Между различными внутренними сервисами, плюс с внешних для системы узлов.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Эти три документа позволяют не теряться в соглашениях, целях и текущих значениях. Люди, ответственные за коммуникации с клиентами точно знают, что предоставляют. Инженеры поддерживают и проектируют решения с четко обозначенными ограничениями. Более подробно с темой SLA, SLO, SLI можно ознакомиться в книге &#34;Site Reliability Engineering&#34; (2016) &lt;a href=&#34;#sre&#34;&gt;[sre]&lt;/a&gt;, написанной инженерами Google.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Организационные_подходы_для_построения_систем_высокой_доступности&#34;&gt;Организационные подходы для построения систем высокой доступности&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Если желаете увеличить доступность системы для внешних пользователей, всегда начинайте анализ с самого верхнего уровня, чтобы не оказаться в ситуации, когда балансировщик трафика с отказоустойчивым кластером стоит за каким-то жалким единственным роутером, который работает лишь по стечению случайностей. Эту проблему всегда необходимо рассматривать именно со стороны пользователя системы или сервиса, который к ней обращается, а не изнутри.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Не_экономить_на_самом_дешевом_железе&#34;&gt;Не экономить на самом дешевом железе&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Выбирать железо стоит исходя не только из его минимальной цены за определенные возможности, а по результатам расчёта ROI, где учитывается его непосредственная цена, его время эксплуатации в системе, наличие специалистов для его обслуживания, гарантийного сервиса и близость поставщиков для его замены по гарантии или для обновления.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Согласованность&#34;&gt;Согласованность&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Компоненты системы должны быть согласованы между собой, например:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Емкость канала должна быть расчётной для узла который на ней висит.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Рабочие инстансы должны иметь столько RAM, которая бы соответствовала работающему там приложению с учётом им потребляемой памяти (в т.ч. установленным лимитам).&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Сервера должны иметь такую ёмкость локального диска для объема операций записи за период, после чего будут действовать механизмы retention во избежание отказов от появления ошибок.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Приложения должны использовать хранилища с учётом их особенностей и ограничений, например: максимальный размер базы, количество столбцов, максимальный размер записи.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Клиенты и серверы должны использовать одни и те же версии протоколов и соответствовать друг другу по API.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Надёжность отдельных компонентов тоже должна быть обоснована и согласована между собой.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;График обслуживания должен быть согласован с временем, когда на систему минимальная нагрузка, либо позволяет SLA. Если это промежуточная система для её клиента, то зависимая система должна учитывать SLA системы от которой зависит и в случае потребности иметь некоторую изоляцию от последней, чтобы предоставить сервис если это возможно, или хотя бы корректно отработать отказ.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Ответственность&#34;&gt;Ответственность&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Ни вендор, ни поставщик программного обеспечения, ни программисты не могут построить высокодоступную и комфортную для пользователя системы. Построение такой системы - это тестирование, интеграция, испытания, верификация приложений и рабочих процессов. Наивно полагать, что развернув определенное ПО на рабочем контуре, вы получите высокодоступную систему, так как это: максимальный MTBF и минимальный MTTR, которые доводятся до нужных значений именно отладкой рабочих процессов сотрудников. Не стоит уповать и на организацию кластеров и средства репликации данных. Без своевременных вмешательств и организации работ по выводу из состоянии деградации система не может быть отказоустойчивой и высокодоступной. Формируйте SLA, SLO, ведите SLI.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Устранение_единых_точек_отказа_single_point_of_failure_spof&#34;&gt;Устранение единых точек отказа (Single Point of Failure (SPOF))&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Анализируйте систему на присутствие в ней элементов, выход из стоя которых может привести к невозможности продолжить исполнение даже в ограниченном режиме. Проще всего начать с анализа цепочек исполнения, зависимостей или data-flow диаграмм. Достаточно пройтись по ключевым обслуживаемым процессам, чтобы уже появилось представление о самых слабых узлах в цепочке. Но далеко не каждый компонент, представляющий собой SPOF, возможно дублировать или устранить иногда по финансовым причинам (слишком дорогое дублирующее железо), ограничения физические (например только один вводной канал) или концептуальное ограничение (например CAP-теорема&lt;a href=&#34;#cap&#34;&gt;[cap]&lt;/a&gt;)&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Консолидация_серверов&#34;&gt;Консолидация серверов&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Вместо использования множества мелких серверов, иногда имеет смысл использовать лишь несколько, но гораздо более мощных для того, чтобы:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;упростить топологию и уменьшить количество узлов&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;сократить затраты на обслуживание (обновление, резервное копирование и т.п.)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;улучшить производительность из-за уменьшения затрат на передачу данных по сети&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Инструментарий для виртуализации и оркестрацией серверов упрощает управление распределенной инфраструктурой, еще и с прослойкой абстракции над железом, но для части задач (такие как базы данных) или большие legacy системы, всё ещё имеет смысл.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Автоматизация_и_оптимизиация&#34;&gt;Автоматизация и оптимизиация&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Чем выше уровень автоматизации - тем меньше требуется время на операции, меньше ответственных за них. Ускорение и автоматизация цикла &#34;сборка-тестирование&#34; добавляет удобства для инженеров, увеличивает количество таких циклов за единицу времени, время тратится более эффективно. СI/CD подходы сильно упрощают раскатывание новых релизов по контурам, тем самым уменьшая и MTTR, и time to market (TTM).&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Типовые_конфигурации_и_общие_репозитории&#34;&gt;Типовые конфигурации и общие репозитории&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Унификация сильно помогает для уменьшения времени на проектирование, тестирование и развертывание новых сервисов. Общие конфигурации и артефакты сильно помогают в этом на всех стадиях от идентификации потребности, до развертывания в production.
Чек-лист:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;список рекомендованного ПО для production&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;репозиторий скриптов развертывания инфраструктуры - Infrastructure as Code&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;репозиторий артефактов (Artifactory, Bintray, GitLab)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;реестр типовых образов (Docker Registry, Amazon ECR, GitLab Container Registry)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;типовые шаблоны для security groups&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Мониторинг_и_оповещение&#34;&gt;Мониторинг и оповещение&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Без мониторинга невозможно разобраться в каком состоянии находится система. Каждое запущенное приложение представляет без сбора метрик, health-checks и логов представляет собой чёрный ящик: что-то подаётся на вход, что-то поступает на выход с не всегда очевидными side-effects. Чтобы это избежать используют health-check интерфейсы и сбор метрик.&lt;br&gt;
Через Health-check интерфейс проверяют живо ли приложение, вместе с пустым ответом приложение может предоставлять ещё и некоторую информацию о своём состоянии. В зависимости от подходов и вариантов процедуры развертывания организуют и автоматические операции, там может быть: перезапуск, оповещение оператора, добавление информации об этом в журнал.&lt;br&gt;
Метрики -  одномоментные показатели состояния ПО и железа, могут быть в виде счётчиков, таймеров, гистограм и т.п. Все они помогают понять в каком состоянии система была, находится и какова динамика изменений. Кроме системных метрик (RPS, QPS, latency, заполненность очередни и т.п.) могут собираться и бизнесовые метрики с информацией из предметной области бизнеса.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Собрать метрики мало - нужно ещё ими воспользоваться, в этом помогают различные инструменты их отображения: Kibana, Grafana, Prometheus, Datadog. Быстрый и удобный UI с дашбордами для просмотра информации о метриках - хорошая инвестиция в комфорт работы и уменьшение MTTR.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;На основе используемых метрик, их граничных значений, алгоритмов определения аномалий, а также появления определенных записей в логах, выстраивается система оповещения о внештатных ситуациях и инцидентах. Слишком строгие настройки могут вызвать ложные оповещения чем будут раздражать операторов, инженеров и портить отчётность. Слишком высокий порог может не показать деградацию системы, что тоже не хорошо. Следует искать приемлемый баланс, следуя рекомендациям вендоров, поставщикам ПО, а также используя инженерные оценки.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Измерение_производительности&#34;&gt;Измерение производительности&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Рассуждая о доступности какого-то сервиса для клиента, мы имеем ввиду, что &lt;strong&gt;все&lt;/strong&gt; компоненты в цепочке исполнения должны иметь время реакции из конкретного временного интервала, иначе уровень сервиса для клиента может упасть до неприемлемо низких значений. Чтобы не столкнуться с непредвиденной деградацией производительности в поддержании высокодоступной системы должны быть использованы:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;&lt;a href=&#34;#wiki_bm&#34;&gt;бенчмаркинг&lt;/a&gt; отдельных компонентов системы&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;нагрузочное или стресс тестирование - подача нагрузки на систему или её изолированную часть и замеры, чтобы определить граничные возможности системы обработать выданную нагрузку. Качество проводимого тестирования сильно зависит от возможности эмулировать паттерн нагрузки как и на боевой системе, организации замеров.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;сбор и анализ метрик производительности во время эксплуатации, могут быть как системные метрики, так и из предметной области.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;stability testing - продолжительное по времени тестирование, проводимое с симуляцией различных условий эксплуатации.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Результаты тестирования сохраняются с указанием версии ПО или железа, чтобы в будущем иметь возможности системы от релиза к релизу. Помогает выявить внесённые изменения, повлекшие к деградации производительности.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Последовательные и систематичные меры дадут возможность не только видеть состояние системы под нагрузкой, понимать границы той самой доступности предоставляемого сервиса, но и видеть причинно-следственные связи от изменений в самой системе или её реакцию на изменение нагрузки. Чем больше будет похожа тестовая нагрузка на нагрузку во время эксплуатации, тем ближе будет соответствие результатам в эксплуатации. Кроме того, обладая данными о фактической производительности компонентов, появляется возможность более точно рассчитать потребности в ресурсах при горизонтальном масштабировании.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Обучение_и_тренинги_персонала&#34;&gt;Обучение и тренинги персонала&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Обучайте людей пользоваться инструментами, рассказывайте об их возможностях влиять на систему, какова их роль в процессе и за что они отвечают. Занятый в эксплуатации человек будет действовать более уверенно и быстро, когда он знает о своих возможностях.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Раздельные_контуры&#34;&gt;Раздельные контуры&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Чтобы процессы разработки и тестирования не влияли на саму эксплуатируемую систему, необходимо разделять среды с различной их целью. Обычно используются следующие:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;sandbox для разработчиков где тестируется новый софт, технологии, железо&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;dev контур для работы над кодом, dev-тестирования, если невозможно развернуть систему для теста на локальном компьютере инженера, в следствии этого должен относительно хорошо поддерживаться, чтобы не замедлять работу инженеров&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;QA контур, может быть несколько, для ручного тестирования, регрессионного, интеграционного, конфигурация ещё ближе к production. Может иметь реплицированные или восстановленные из резервных копий данные с production.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Staging - практически повторяет по топологии production и его возможности. Все изменения тестируются перед тем, как попасть в эксплуатационный контур. Мониторинг, сбор логов и метрик практически всегда обязателен тут. Играет важную роль для эмуляции случаев произошедших в эксплуатации и проверке гипотез.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Producton - он же эксплуатационный контур. Контуров может быть несколько для создания избыточности, если она требуется, раскатывают обновления в таком случае последовательно, чтобы иметь возможность быстро переключиться на резервный. Либо избыточный контур находится в другом дата-центре, чтобы иметь возможность обработать отказ всего ДЦ.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Заключение&#34;&gt;Заключение&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Рассмотрели, пусть и крайне поверхностно, но практически все (я надеюсь) концепции и общие подходы построения высокодоступных систем. Как выше уже определили, надёжность - это максимальное время работы между сбоями и минимальное время восстановления. За всем этим скрывается:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Надёжность компонентов (будет в следующей статье из серии)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Работа с концептуальными ограничениями в распределённых вычислениях.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Избыточность компонентов, чтобы иметь устойчивость к сбоям эксплуатируемых узлов.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Прозрачный или хотя бы быстрый процесс аварийного переключения.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Максимально быстрый процесс от идентификации сбоя, до его решения.&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Что ещё рекомендуется изучить по данной теме:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Большая часть тем гораздо глубже описана в книге &#34;Site Reliability Engineering&#34;&lt;a href=&#34;#sre&#34;&gt;[sre]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;По эксплуатации и дизайну приложений в AWS рекомендую &#34;AWS Well-Architected Framework&#34;&lt;a href=&#34;#aws-waf&#34;&gt;[aws-waf]&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Отличная книга &#34;Distributed Systems. Concurrency and Consistency (Matthieu Perrin, 2017)&#34; &lt;a href=&#34;#ds1e&#34;&gt;[ds1e]&lt;/a&gt;, которая поможет при выборе инструментария, независимо on-premise, cloud или собственного решения. Отличный гайд по &#34;нюансам&#34; и подводным камням, которые иногда не заметны под маркетинговыми лозунгами.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Знакомство с основами распределенных алгоритмов, границами их применимости, рекомендую начать с Distributed Systems. An Algorithmic Approach (2013). В книге рассказывается о таких важных алгоритмах, как: выбор мастера в кластера, основах трейсинга с использованием алгоритмов обхода дерева, скедулинга задач среди воркеров.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Ссылки&#34;&gt;Ссылки&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist bibliography&#34;&gt;
&lt;ul class=&#34;bibliography&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;std610&#34;&gt;&lt;/a&gt;[std610]  &lt;a href=&#34;https://pdfs.semanticscholar.org/dce9/9209120ebed7f5d68e3644fdcd160d4c366c.pdf&#34;&gt;IEEE Standard Glossary of Software Engineering Terminology&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;hadr&#34;&gt;&lt;/a&gt;[hadr] High Availability and Disaster Recovery: Concepts, Design, Implementation, (Klaus Schmidt, 2006)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;cap&#34;&gt;&lt;/a&gt;[cap] &lt;a href=&#34;https://towardsdatascience.com/cap-theorem-and-distributed-database-management-systems-5c2be977950e&#34;&gt;CAP Theorem and Distributed Database Management Systems (Syed Sadat Nazrul, 2018)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;wiki_bm&#34;&gt;&lt;/a&gt;[wiki_bm] &lt;a href=&#34;https://en.wikipedia.org/wiki/Benchmark_(computing)&#34;&gt;wiki: Benchmark (computing)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;wiki_raid&#34;&gt;&lt;/a&gt;[wiki_raid] &lt;a href=&#34;https://en.wikipedia.org/wiki/RAID&#34;&gt;wiki:RAID&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;hat&#34;&gt;&lt;/a&gt;[hat] &lt;a href=&#34;https://arxiv.org/abs/1302.0309v2&#34;&gt;Highly Available Transactions: Virtues and Limitations
(Extended Version) (Peter Bailis, Aaron Davidson, Alan Fekete, Ali Ghodsi, Joseph M. Hellerstein, Ion Stoica, 2013)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;ds1e&#34;&gt;&lt;/a&gt;[ds1e] &lt;a href=&#34;https://www.elsevier.com/books/distributed-systems/perrin/978-1-78548-226-7&#34;&gt;Distributed Systems. Concurrency and Consistency (Matthieu Perrin, 2017)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;pgsql-tr&#34;&gt;&lt;/a&gt;[pgsql-tr] &lt;a href=&#34;https://www.postgresql.org/docs/11/transaction-iso.html&#34;&gt;PostgeSQL Documentation. Transaction Isolation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;mssql-si&#34;&gt;&lt;/a&gt;[mssql-si] &lt;a href=&#34;https://docs.microsoft.com/en-us/dotnet/framework/data/adonet/sql/snapshot-isolation-in-sql-server&#34;&gt;Snapshot Isolation in SQL Server&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;oracle-si&#34;&gt;&lt;/a&gt;[oracle-si] &lt;a href=&#34;https://docs.oracle.com/cd/E17276_01/html/gsg_xml_txn/cxx/isolation.html#snapshot_isolation&#34;&gt;Oracle DB. Isolation&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;abadi&#34;&gt;&lt;/a&gt;[abadi] &lt;a href=&#34;http://cs-www.cs.yale.edu/homes/dna/papers/abadi-pacelc.pdf&#34;&gt;Consistency Tradeoffs in Modern Distributed Database System Design (Yale Univercity, 2012)&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;sre&#34;&gt;&lt;/a&gt;[sre] Site Reliability Engineering (Betsy Beyer, Chris Jones,
Jennifer Petoff &amp;amp; Niall Richard Murphy), 2016&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;aws-waf&#34;&gt;&lt;/a&gt;[aws-waf] &lt;a href=&#34;https://d1.awsstatic.com/whitepapers/architecture/AWS_Well-Architected_Framework.pdf&#34;&gt;AWS Well-Architected Framework&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Сбои и восстановление работоспобности систем</title>
      <link>/post/2019/02-distsys/</link>
      <pubDate>Sun, 13 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019/02-distsys/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;
&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul class=&#34;sectlevel1&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Причины_простоев&#34;&gt;Причины простоев&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Классификация_сбоев&#34;&gt;Классификация сбоев&lt;/a&gt;
&lt;ul class=&#34;sectlevel2&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Малые_сбои&#34;&gt;Малые сбои&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Крупные_сбои&#34;&gt;Крупные сбои&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Сбои_и_связанные_с_ними_процессы&#34;&gt;Сбои и связанные с ними процессы&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Таймлайн&#34;&gt;Таймлайн&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Цена_доступности&#34;&gt;Цена доступности&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Пример_Повышение_надежности_за_счет_создания_кластера_из_двух_узлов&#34;&gt;Пример: Повышение надежности за счет создания кластера из двух узлов.&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Арифметика_доступности_итоги&#34;&gt;Арифметика доступности: итоги&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Ссылки&#34;&gt;Ссылки&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Причины_простоев&#34;&gt;Причины простоев&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Простои в работе систем и сервисов разделяют на плановые и внеплановые.
Под плановыми простоями обычно подразумевается остановка в ранее обозначенном сервисном окне (maintenance window) с целью проведения модернизации оборудования, обновления ПО, обслуживания, миграции данных. Подобную остановку коснемся в данной статье лишь поверхностно.
Внеплановые простои, или сбои в работе, происходят по следующим причинам:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Отказа в единственном и критически важном узле (single point of failure)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Система эксплуатируется вне лимитов предусмотренных во время ее проектирования&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Программные ошибки&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Ошибки обслуживающего персонала или пользователей&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Проблемы с целостностью данных&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Stephanie Balaouras приводит &lt;a href=&#34;#sr&#34;&gt;[sr]&lt;/a&gt;  следующую статистику по причинам сбоев:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;./images/outages.png&#34; alt=&#34;Outages&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Классификация_сбоев&#34;&gt;Классификация сбоев&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;При анализе и проектировании систем и сервисов прежде всего смотрят на связанные с ними бизнес-процессы. Исходя из важности для организации и условий эксплуатаций последних  (сколько выручки они приносят, как влияют на выполнение ключевых функций, под какие ограничения они подпадают и т.п.) и определяют размер ущерба в случае сбоя в зависимости от временных периодов. Вполне очевидно, что это не единственно возможный вид классификации и различные организации, и даже различные подразделения одной организации могут классифицировать сбои по своему преследуя свои цели, например:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Классифицировать по региону затронутому сбоем (глобальный, область или штат, район);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;По причинам отказа (перегрузка, пожар, упавшее дерево, аппаратная ошибка);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;По компоненту который вызвавший отказ (отказ на сетевом канале, отказ сервера, неисправность UPS и так далее)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;По важности для ведения бизнеса (не существенный, значимый, важный, критически важный)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Как правило подобные классификации используются при формировании списка от чего организация должна защищаться, планировании как именно это будет происходить, но подобная тема за рамками текущей статьи, поэтому вернемся с классификации по важности для бизнеса.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Опираясь от важности затрагиваемых бизнес-процессов или функций и продолжительности сбоя Клаус Шмидт &lt;a href=&#34;#hadr&#34;&gt;[hadr]&lt;/a&gt; предлагает следующую классификацию:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-topbot grid-all&#34; style=&#34;width: 80%;&#34;&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 33.3333%;&#34;&gt;
&lt;col style=&#34;width: 33.3333%;&#34;&gt;
&lt;col style=&#34;width: 33.3334%;&#34;&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Категория&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Максимальное время малого сбоя&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Максимальное время крупного сбоя&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Непрерывная работа&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2ч&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Бизнес-функция&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;10мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;8ч&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ключевые бизнес-процессы&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1 рабочий час&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3 дня&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ведение бизнеса&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1 рабочий день&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1 неделя&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Подобная классификация приведена лишь для наглядности, при разработке плана по восстановлению после отказов и при проектировании системы устойчивой к отказам стоит руководствоваться исключительно фактическими потребностями и регламентами работы организации.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Малые_сбои&#34;&gt;Малые сбои&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Малые сбои возникают каждый день на крупных системах даже если организация использует и все планы по поддержанию ведения бизнеса и восстановления после сбоев. Вероятность появления подобных сбоев высока, но связанные с ними последствия и потери достаточно мало, в эту категорию можно отнести отказы со следующими признаками:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Сбой произошел в работе изолированного компонента или системы, затронута лишь один бизнес-процесс или один сегмент критической бизнес-функции.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Рабочие процессы могут зачастую исполняться в нормальном режиме без прерывания.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Важные бизнес-функции продолжают исполняться даже спустя некоторое время после обнаружения отказа&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Отказ единственного сервиса или системы устраняется в ходе обычной рабочей деятельности или автоматически.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Пример: отказ одного сервера, накопителя, блока питания. Отказ создает проблемы в функционировании организации, но не требует запуска процедур по ручному восстановлению нормального функционирования.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Крупные_сбои&#34;&gt;Крупные сбои&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Вероятность возникновения крупных сбоев мала, но влияние на ведение бизнеса огромно. Подобные типы сбоев включат в себя:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Сбой прерывает нормальное функционирование всех или большинства бизнес-процессов.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Сбой из-за того, что все или большинство из систем и сервисов становятся недоступными.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Сбой включает в себя выход из строя оборудования, сети организации или ключевых подсетей.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В случае возникновения подобного уровня сбоя в работе организации вам необходимо определить какая часть из плана business continuity / disaster recovery (BC/DR) вам необходимо использовать и какие команды будут ответственны за выполнение работ по восстановлению. Планирование и обработка таких событий будет освещено в последующих статьях по аварийному восстановлению.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect2&#34;&gt;
&lt;h3 id=&#34;_Сбои_и_связанные_с_ними_процессы&#34;&gt;Сбои и связанные с ними процессы&lt;/h3&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Если рассматривать сбои исключительно с точки зрения бизнеса, то нельзя не обратить внимание на тот факт, что любая активность, направленная на предотвращение сбоя или его устранение это работа с рисками и затратами. Меру по предотвращению сбоя можно назвать инвестицией в отказоустойчивость, тогда как восстановление после сбоя есть не что как работа с приемлемыми рисками. Либо неприемлемыми, но тогда бизнес будет существовать до первого инцидента, который приведет к его закрытию.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Оценка рисков (в англоязычной литературе risk assessment) - это отдельная большая тема, которая раскрывается и в управлении проектом, и продуктом, и во время анализа требований, и для составления планов BC/DR. Более подробно, но все же относительно поверхностно она будет рассмотрена в последующих статьях, для более глубокого изучения приведу дополнительные ссылки.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_Высокая_доступность_high_availability_ha&#34;&gt;Высокая доступность / High Availability / HA&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И так, “высокая доступность” - это решение бизнеса по обеспечению его собственного непрерывного функционирования.
Технических трактовок для HA существует большое множество, некоторые из них:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Storage Network Industry Association &lt;a href=&#34;#snia&#34;&gt;[snia]&lt;/a&gt;: The ability of a system to perform its function continuously (without interruption) for a significantly longer period of time than the reliabilities of its individual components would suggest.
High availability is most often achieved through failure tolerance. High availability is not an easily quantifiable term. Both the bounds of a system that is called highly available and the degree to which its availability is extraordinary must be clearly understood on a case-by-case basis.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;DigitalOcean.com: In computing, the term availability is used to describe the period of time when a service is available, as well as the time required by a system to respond to a request made by a user. High availability is a quality of a system or component that assures a high level of operational performance for a given period of time.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Klaus Schmidt &lt;a href=&#34;#hadr&#34;&gt;[hadr]&lt;/a&gt;: High availability is the characteristic of a system to protect against or recover from minor outages in a short time frame with largely automated means.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Более детально основы HA, дизайн HA систем и затраты на его обеспечение будут рассмотрены в следующей статье.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect3&#34;&gt;
&lt;h4 id=&#34;_Аварийное_восстановление_disaster_recovery_dr&#34;&gt;Аварийное восстановление / Disaster Recovery / DR&lt;/h4&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Те сбои, которые было невозможно предотвратить через комплекс мер для HA приводят к тому, что реализация бизнес-процессов сильно замедляется, либо прекращается вовсе (см. Крупные сбои). Под набором планов (крайне желательно, чтобы они были) работ и скрывается “аварийное восстановление” или “business continuity / disaster recovery” (BC/DR).
Определение от Klaus Schmidt&lt;a href=&#34;#hadr&#34;&gt;[hadr]&lt;/a&gt;: Disaster recovery is the ability to continue with services in the case of major outages, often with reduced capabilities or performance. Disaster-recovery solutions typically involve manual activities.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Более подробно организационные меры и технические решения для обработки крупных сбоев и восстановление после них рассмотрим в последующих статьях.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Таймлайн&#34;&gt;Таймлайн&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Перед тем как перейти к анализу сбоев, их оценке и планирования их обработки следует определить что именно происходит до, во время и после сбоя, а также несколько самых часто используемых терминов которые используются в этой области. Ниже представлена диаграмма с типичными фазами и последовательностью действий для восстановления.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;./images/timeline.png&#34; alt=&#34;Timeline&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;em&gt;Maximum tolerable downtime (MTD)&lt;/em&gt; или &lt;em&gt;максимальное время простоя&lt;/em&gt; - максимальное время которое бизнес может допустить в случае отсутствия или недоступности конкретных бизнес функций. Различные бизнес-функции имеют различный показатели MTD в зависимости от их критичности - чем важнее функция для бизнеса, тем короче должен быть MTD для нее. Простой можно разделить на две фазы: RTO и WRT.&lt;br&gt;
&lt;em&gt;Recovery time objective (RTO)&lt;/em&gt; или &lt;em&gt;время доступное на восстановление системы&lt;/em&gt; - время, использующееся на восстановление поврежденной инфраструктуры и ресурсов. В этой фазе система запускается, восстанавливаются данные из резервных копий.&lt;br&gt;
&lt;em&gt;Work recovery time (WRT)&lt;/em&gt; или &lt;em&gt;время восстановления работы&lt;/em&gt;. WRT необходимо декларировать в MTD так как это именно то время, которое необходимо на восстановление работоспособности бизнес-функций, когда происходит устранение целостности данных, синхронизация потоков данных, валидация данных полученных вручную и их добавление к имеющимся наборам данных. Без этой фазы крайне тяжело достичь требований полного восстановления с использованием обычных рабочих процессов без внесения дополнительных для бизнеса риска и без уменьшения его эффективности.&lt;br&gt;
&lt;em&gt;Recovery point objective (RPO)&lt;/em&gt; - максимально допустимое количество данных, которые бизнес может позволить потерять. На основе этого показателя утверждаются процедуры проведения транзакций, репликаций, создания резервных копий и их расписание. Так как у разных систем различные требования к RTO и RPO, то при эксплуатации пытаются найти экономический баланс между стоимостью эксплуатации и потерями. Ниже список технологий и подходов, применяемых там:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;0сек - 10 сек - синхронные репликация или зеркалирование (mirroring)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;10 сек - несколько минут - асинхронная репликация&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Несколько минут - несколько часов - периодическая репликация&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Несколько часов - неделя - резервное копирование&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Соответственно:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;#1, #2 - кластеризация внутри эксплуатируемого контура (production environment) и репликация на запасной контур&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;#3 - ручная миграция на запасной контур&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;#4 - восстановление из резервной копии, естественно вручную&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В случае использовании репликации важно знать алгоритм переключения I\O на реплику при недоступности master узла. В случае резервного копирования - время восстановления из резервной копии, это зависит от: объема данных, скорости передачи данных, технологий резервного копирования и их ограничений. Более подробно эти технические нюансы рассмотрим в последующих статьях.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И так система обычно проходит через следующую последовательность состояний прежде чем будет полностью восстановлена:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-all grid-all stretch&#34;&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 4%;&#34;&gt;
&lt;col style=&#34;width: 16%;&#34;&gt;
&lt;col style=&#34;width: 40%;&#34;&gt;
&lt;col style=&#34;width: 40%;&#34;&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;#&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Фаза&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Защита&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ограниченные меры (дешевле)&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Потеря данных (RPO)&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Синхронная репликация на резервный контур (очень дорого, увеличивает время на проведение транзакции)&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Резервный контур разворачиватся из резервных копий. Процесс может занять дни.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Аварийное событие и простой&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Автоматический процедура по перенаправлению трафика на резервный контур пока основной контур восстанавливается. На резервный контур должна быть настроена репликация.&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Ручной запуск приложений на втором контуре, дополнительные работы по перенаправлению трафика, прогрева кэшей.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Деградация&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Работа на резервном контуре до восстановления основного. Если это единственный контур, то последующий большой сбой приведет к полному простою системы и катастрофическим последствиям.&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Тоже самое&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;4&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Запланированный простой&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Относительно небольшое время простоя для миграции данных из резервного контура на основной перед его запуском в эксплуатацию.&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Тоже самое&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Даже без фактически расчетов не трудно заметить, что в случае наличия зависимости между доступностью системы и дохода бизнеса, например потери выручки, осуществление продаж, потеря потенциальных заказчиков и т.д. Можно изобразить зависимость между затратами на восстановление и то сколько времени тратится на него.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;./images/cost-dt.jpg&#34; alt=&#34;Cost of downtime 2&#34; width=&#34;400&#34; height=&#34;400&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Чем больше времени тратится на восстановление, тем больше потери (и они не линейны), но тем дешевле мероприятия по возобновлению работы так как требуется меньше дополнительных человеко-часов и ресурсов на эти процедуры.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Цена_доступности&#34;&gt;Цена доступности&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Вернемся к формуле доступности из первой статьи.&lt;br&gt;
&lt;code&gt;A  = MTBF / (MTBF + MTTR)&lt;/code&gt;&lt;br&gt;
Видно, что для увеличения доступности нужно либо увеличивать &lt;code&gt;MTBF&lt;/code&gt;, либо уменьшать &lt;code&gt;MTTR&lt;/code&gt;. Очевидно, что на компоненты склонные к отказам как-то повлиять тяжело, они просто падают с некоторой вероятностью, соответственно легче сфокусироваться на &lt;code&gt;MTTR&lt;/code&gt;. Таким образом если проблемными частями системы являются отдельные компоненты, то самым простым способом существенно увеличить доступность системы - дублировать их с автоматическим переключением нагрузки на резервные или изначально избыточные части: зеркалирование накопителей, настройка аварийного переключения (failover) для кластеров. Таким образом потенциальные простои системы могут быть уменьшены с дней до считанных минут.
Пример. Минута простоя обходится в $100 (достаточно низкое значение). Уменьшаем простой вследствии сбоя с 5 часов до 20 минут, тогда это позволит не потерять $28000 (280 мин * $100). Если подобный сбой происходит раз в два месяца, то реализация подобных вложений позволит не потерять уже $168000 за год. Вполне очевидно, что это стоит того чтобы вложить в увеличение надежности $20000 или $50000, особенно если время жизни такой системы будет больше чем 1 год.
Время добавить немного арифметики в повествование для того, чтобы иметь представление как вложения в нее повлияют на бизнес. Для примера возьмем расчет экономии между до и после затрат на увеличение надежности. Экономия (\$S\$) будет разницей между риском &#34;до&#34; (\$R_B\$) и риском &#34;после&#34; (\$R_A\$), т.е.: \$S=R_B-R_A\$. Затраты на реализацию - \$C_M\$. Таким образом можно посчитать ROI в процентах:&lt;br&gt;
\$ROI = S/C_M\$&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Очевидно и просто, но расчет рисков все-таки несколько более объемный. В рисках три показателя: влияние (impact) на систему, продолжительность (duration) сбоя и вероятность (likelihood).&lt;br&gt;
&lt;strong&gt;Влияние&lt;/strong&gt;. Процент пользователей, которые были охвачены сбоем. Если это запланированная перезагрузка сервера в 3 утра на обслуживание, то это может быть 10%. Если это отказ ключевого сервера БД в середине рабочего дня - 100%.&lt;br&gt;
&lt;strong&gt;Продолжительность&lt;/strong&gt;. Продолжительность сбоя во времени когда пользователи не могут воспользоваться некоторой функцией или ресурс недоступен. Обычно измеряется в минутах.&lt;br&gt;
&lt;strong&gt;Вероятность&lt;/strong&gt;. Количество раз, когда компонент может приводить к сбою за ожидаемое время эксплуатации системы. Например, если отказ одного из компонентов случается раз в месяц, то за пять лет вероятно он откажет 60 раз. Редкие события могут и не случаться пока система эксплуатации, например аппаратный роутер будет работать 5 лет без сбоев, тогда вероятность сбоя можно оценить в 0.01 или меньше. Эти показатели вероятностные и выставляются на основе прогнозов и на основе опыта людей, которые их уже использовали.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И так, каждое событие (\$E\$) будет состоять из влияния (\$I\$), продолжительности (\$D\$) и вероятности (\$L\$).&lt;br&gt;
\$E = I \cdot D \cdot L\$&lt;br&gt;
Соответственно состояние “до” \$E_{Bx}\$ компонента x и “после” \$E_{Ax}\$. Другой важный фактор - стоимость простоя (\$C_D\$), выразим его в долларах за минуту. Большинство компаний не имеют информации о том сколько стоит время простоя, аналитические и консалтинговые компании (такие как IDC или Gartner) публикуют среднее значение по отрасли, а не по каким-то выбранным реализациям. И так, общая формула риска для n компонентов до:&lt;br&gt;
\$R_B=C_D \cdot \sum\_{x=1}^n E_{Bx} \$&lt;br&gt;
Риск после:&lt;br&gt;
\$R_A=C_M+(C_D \cdot \sum\_{x=1}^n E_{Ax}) \$&lt;br&gt;
Где \$С_M\$ - цена имплементации.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Нужно отметить тот факт, что сам по себе показатель стоимости простоя нелинеен для большинства систем. В случае нескольких секунд или минут он может зачастую может остаться без реакции на него из-за использования retry и backpropagation техник или вызовет лишь незначительное неудобство для пользователя. Тогда как простой в час и выше может принести ощутимый ущерб бизнесу. Этот параметр всегда нужно рассматривать исключительно с точки зрения конкретного бизнеса и его модели.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Пример_Повышение_надежности_за_счет_создания_кластера_из_двух_узлов&#34;&gt;Пример: Повышение надежности за счет создания кластера из двух узлов.&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Средних размеров сервисная компания использует РСУБД и от доступности которой зависит большинство бизнес-функций компаний по получению и обработке заказов. Ожидаемый срок эксплуатации системы - 5 лет, цена простоя $60 за минуту или $3600 в час. Чтобы использовать РСУБД в кластере, нужно:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;Купить сервер&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Поставить второй сервер на колокейшн&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Установить и настроить кластерно ПО на оба хоста для репликации и * переключения ролей в кластере&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Обновить ПО использующее этот кластер&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Заключить договор на поддержку кластера (платная поддержка)&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Цена имплементации (\$C_M\$):&lt;br&gt;
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/example-01.png&#34; alt=&#34;Example01&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Риски до имплементации:&lt;br&gt;
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/example-02.png&#34; alt=&#34;Example02&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Риски после:&lt;br&gt;
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/example-03.png&#34; alt=&#34;Example03&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Итого экономия за 5 лет от повышения доступности составляет:&lt;br&gt;
\$S=R_B-R_A-C_M\$&lt;br&gt;
&lt;code&gt;$600000-$122250-$96000=$477750&lt;/code&gt;&lt;br&gt;
Детальная калькуляция с описанием допущений доступна в &lt;a href=&#34;https://docs.google.com/spreadsheets/d/16Ga8WSc5xxufbSAabo5vyviKlbLundlm1cjsZCi2Qxw/edit?usp=sharing&#34;&gt;Example-01: Risk calculation (Google Sheet)&lt;/a&gt;.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Арифметика_доступности_итоги&#34;&gt;Арифметика доступности: итоги&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Рассмотренный пример, пусть и в достаточно упрощенной форме, демонстрирует общий подход как на основе достаточно простых калькуляций сделать прогноз по окупаемости вложений в доступность сервиса. Как уже было описано ранее, увеличение доступности есть увеличение MTBF, либо уменьшение MTTR и второй вариант является, чаще всего, более дешевым из-за улучшения рабочих процедур, использования лучших практик, а не за счет покупки крайне дорогого оборудования, которое все же будет иметь вероятность возникновения сбоя из-за каких-либо дефектов, ошибок так и в силу внешних факторов.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Таким образом можно схематически отобразить зависимость между затратами и увеличением доступности:&lt;br&gt;
&lt;span class=&#34;image&#34;&gt;&lt;img src=&#34;./images/investments.jpg&#34; alt=&#34;investments&#34; width=&#34;600&#34; height=&#34;600&#34;&gt;&lt;/span&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;На изображении также представлен “стек” практик, которые следует последовательно (снизу вверх) вводить для достижения требуемого уровня надежности системы. Именно за счет последовательности в управлении надежности эта самая надежность и достигается, так как без нижележащего уровня высокий уровень будет иметь не так много смысла и даже его использование может быть осложнено или невозможно в принципе.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Более подробно эти практики рассмотрим в последующих статьях.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Ссылки&#34;&gt;Ссылки&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;ulist bibliography&#34;&gt;
&lt;ul class=&#34;bibliography&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;sr&#34;&gt;&lt;/a&gt;[sr] 3 Steps to IT Resilience with Forrester - &lt;a href=&#34;https://vimeo.com/182883763&#34; class=&#34;bare&#34;&gt;https://vimeo.com/182883763&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;hadr&#34;&gt;&lt;/a&gt;[hadr] High Availability and Disaster Recovery: Concepts, Design, Implementation, Klaus Schmidt (2006)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;snia&#34;&gt;&lt;/a&gt;[snia] SNIA: Dictionary - &lt;a href=&#34;https://www.snia.org/education/dictionary&#34; class=&#34;bare&#34;&gt;https://www.snia.org/education/dictionary&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;bcdr&#34;&gt;&lt;/a&gt;[bcdr] Business Continuity and Disaster Recovery Plan for Information Security (Heng, 1996)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;a id=&#34;bcp&#34;&gt;&lt;/a&gt;[bcp] BCP - &lt;a href=&#34;https://en.wikipedia.org/wiki/Business_continuity_planning&#34; class=&#34;bare&#34;&gt;https://en.wikipedia.org/wiki/Business_continuity_planning&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Системы с высокой доступностью</title>
      <link>/post/2019/01-distsys/</link>
      <pubDate>Fri, 11 Jan 2019 00:00:00 +0000</pubDate>
      <guid>/post/2019/01-distsys/</guid>
      <description>&lt;div id=&#34;toc&#34; class=&#34;toc&#34;&gt;
&lt;div id=&#34;toctitle&#34;&gt;Table of Contents&lt;/div&gt;
&lt;ul class=&#34;sectlevel1&#34;&gt;
&lt;li&gt;&lt;a href=&#34;#_Связь_с_другими_областями_business_continuity&#34;&gt;Связь с другими областями (business continuity)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Почему_это_нужно_для_бизнеса&#34;&gt;Почему это нужно для бизнеса&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&#34;#_Математика_доступности&#34;&gt;Математика доступности&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Серия статей, цель которых осветить вопросы проектирования и эксплуатации информационных систем и сервисов с требуемым для организации уровнем надежности. Введение в проблематику, освещаются ключевые концепции, связанность с другими вопросами ведения деятельности организации. Статьи предназначены преимущественно для руководителей проектов, собственников продуктов, а также для технических специалистов занятых в проектировании и организации работ.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Данная статья является первой в серии, примерный состав серии:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Системы с высокой доступностью и аварийное восстановление. Введение. (эта статья)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Системы с высокой доступностью и аварийное восстановление. Сбои: причины и классификация.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Высокая доступность: концепции, общие практики построения и сопровождения.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Аварийное восстановление: основы&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Аварийное восстановление: восстановление после сбоя&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Архитектура высокодоступных систем: основы&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Архитектура высокодоступных систем: базовые требования и сценарии отказа обслуживания&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Архитектура высокодоступных систем: расчет надежности&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;С вопросами проектирования и эксплуатации информационных систем сейчас сталкиваются практически в любой отрасли и сфере деятельности человечества где есть потребность в автоматизации и информационной поддержки. Довольно часто, эта автоматизация или информационная поддержка могут сами быть критически важными элементами процессов, обеспечивающих функционирование организации, например быть неотъемлемой частью основного бизнес-процесса или же сами являться продаваемой услугой. Так как от них начинает зависеть сама реализация деятельности или непосредственное получение дохода, то практически сразу же возникает и вопрос их надежности и согласованности с ограничениями и условиями ведения этой самой деятельности.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Связь_с_другими_областями_business_continuity&#34;&gt;&lt;a id=&#34;bc&#34;&gt;&lt;/a&gt;Связь с другими областями (business continuity)&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Данная тема практически всегда рассматривается как часть другой большой темы - обеспечение непрерывности ведения бизнеса/деятельности &lt;a href=&#34;https://en.wikipedia.org/wiki/Business_continuity&#34;&gt;(business continuity)&lt;/a&gt;, которая отвечает за меры по обеспечению доступа к ресурсам для критически важных для организации активностей. К сожалению далеко не все организации руководствуются какими бы то ни было стандартами (региональными, отраслевыми, даже собственными), регламентами или соглашениями. Но при достижении определенного масштаба или увеличения важности информационной системы становится понятно, что дешевле предотвратить инцидент или как-то его обработать, чем столкнуться с его последствиями без заранее предпринятых для его ликвидации мер. Довольно очевидно, что в таких случаях исходят из потребностей организации, а уже на основе них формируются и требования к обеспечению непрерывности функционирования организации через защитные меры.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Почему_это_нужно_для_бизнеса&#34;&gt;&lt;a id=&#34;why&#34;&gt;&lt;/a&gt;Почему это нужно для бизнеса&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Как правило в обеспечении надежности эксплуатируемой организацией системы стоит начинать с потребностей самой организации.  Для этого нужно структурировать ее цели и потери которые могут вызвать отказы системы, их масштабы и показатели. Обычно цели организации определяются через уже установленные стандарты business continuity и через управление рисками, но эта тема вне серии статей. Клаус Шмидт в книге “High availability and disaster recovery. Concepts, design, implementation” предлагает следующую классификацию для описания ущерба организации в случае отказа:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Прямые затраты&lt;/strong&gt; - затраты на ремонт, закупку нового оборудования, восстановление работоспособности&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Дополнительное рабочее времени&lt;/strong&gt; - непрямые затраты связанные с обработкой любого инцидента специалистами&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Потерянное эффективное рабочее время&lt;/strong&gt; - также непрямые затраты, связанные с невозможностью выполнения бизнес-задач персоналом, работу которых затронул отказ.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;&lt;strong&gt;Потерянная выручка&lt;/strong&gt; - невозможность обработать транзакции (любого вида) от экономического агента.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-topbot grid-all&#34; style=&#34;width: 60%;&#34;&gt;
&lt;caption class=&#34;title&#34;&gt;Table 1. Потери вызванные сбоем&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 33.3333%;&#34;&gt;
&lt;col style=&#34;width: 33.3333%;&#34;&gt;
&lt;col style=&#34;width: 33.3334%;&#34;&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Известные&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Оценочные&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Выручка&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Потеря выручки&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Потерянное эффективное рабочее время&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Затраты&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Прямые затраты&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Дополнительное рабочее время&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Наиболее очевидная цена сбоя и простоя системы и вероятно наиболее затратная - уменьшение пользовательской продуктивности. Фактическая цена простоя зависит от того на какую пользовательскую деятельность сбой повлиял и какое количество пользователей он затронул.
Простой пример:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Во внутренней инфраструктуре фирме, предоставляющей некоторый онлайн-сервис произошел сбой, в результате которого сотрудники потеряли возможность работать с тестовыми контурами (test environment) в течении двух дней.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Пользователи разработчики и тестировщики со средней ставкой в $60 за час, сбой в инфраструктуре привел к невозможности работы для 30 человек.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Восстановление работоспособности силами двух администраторов привел к тратам на 16 сверхурочных рабочих часов по той же ставке.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Разработчики работали над исправлением ряда дефектов и тремя новыми функциями для сервиса, выпуск новой версии сдвинулся на три дня. Согласно расчетам вывод новых функций должен приносить дополнительно по $21000 выручки в день. Более того, один из дефектов сильно затрудняет работу сотрудников клиента, чем он недоволен и руководителю организации или менеджеру продукта приходится тратить дополнительные усилия на то, чтобы дополнительно проинформировать клиента, возможно предпринять какие-то еще действия, чтобы тот в целом был удовлетворен оказываемым сервисом и продолжал поддерживать или даже увеличивать выручку организации.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И так имеем следующий список затрат. Простой в работе для разработчиков и тестировщиков:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;code&gt;$50 * 8 часов * 2 дня * 30 человек = $24000&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Сверхурочные для администраторов:&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;code&gt;$50 * 16 часа * 2(коэффициент за сверхурочные) = $1600&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Недополученная выручка:&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;&lt;code&gt;$21000 * 3 дня = $63000&lt;/code&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Пример крайне поверхностный и окончательный подсчет ущерба от сбоя зависит от правил учета затрат в организации и текущих планов по выручке. Если план включал не только те три разрабатываемые фичи, тогда имеет смысл использовать &lt;a href=&#34;https://www.leadingagile.com/2015/06/an-introduction-to-cost-of-delay/&#34;&gt;cost of delay&lt;/a&gt; показатель и для более отдаленных релизов. Но не стоит все затраты, понесенные во время сбоя, списывать на его ликвидацию.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Кроме выше изложенных потерь к последствиям сбоя можно отнести:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Уменьшение удовлетворения клиентов;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Уменьшение морали сотрудников;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Репутационные потери;&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Падение стоимости акций компании (если такие имеются);&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Юридическая ответственность в случае несоответствия заявленным стандартам или договорам.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;На основе известных понесенных или потенциальных потерь выручки и затрат на восстановление работоспособности уже можно планировать меры по минимизации ущерба. При наличии информации о стоимости фактического простоя, подобные меры обосновываются для владельцев крайне просто (с фактами не спорят), а интересы сторон уже известны.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;sect1&#34;&gt;
&lt;h2 id=&#34;_Математика_доступности&#34;&gt;&lt;a id=&#34;availability-math&#34;&gt;&lt;/a&gt;Математика доступности&lt;/h2&gt;
&lt;div class=&#34;sectionbody&#34;&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;И так, в принципе очевидно - простой стоит денег, причем немалых. И чем большее число пользователей было затронуто отказом и чем значительнее затронутые бизнес-процессы, тем дороже этот самый простой обходится. Нет смысла абсолютно точно считать понесенные убытки, чтобы убедиться в их больших размера, пример:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;imageblock&#34;&gt;
&lt;div class=&#34;content&#34;&gt;
&lt;img src=&#34;./images/cod.png&#34; alt=&#34;Cost of downtime&#34;&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Источник: &lt;a href=&#34;https://www.ecessa.com/blog/downtime-costs/&#34;&gt;https://www.ecessa.com/blog/downtime-costs/&lt;/a&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Собственно формула расчет доступности:&lt;br&gt;
&lt;code&gt;A  = MTBF / (MTBF + MTTR)&lt;/code&gt;&lt;br&gt;
&lt;code&gt;A&lt;/code&gt; - собственно сам показательно доступности&lt;br&gt;
&lt;code&gt;MTBF&lt;/code&gt; - mean time between failures (среднее время между отказами)&lt;br&gt;
&lt;code&gt;MTTR&lt;/code&gt; - maximum time to resolve (максимальное время восстановления)&lt;br&gt;&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Для удобства &lt;code&gt;A&lt;/code&gt; умножают на 100, чтобы получить процент бесперебойной работы, именно из этого показателя формируется всем известная “доступность” по количеству девяток. На всякий случай таблица с ними для 24х7 сервисов:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-topbot grid-all&#34; style=&#34;width: 90%;&#34;&gt;
&lt;caption class=&#34;title&#34;&gt;Table 2. SLA для 24x7 сервисов&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 25%;&#34;&gt;
&lt;col style=&#34;width: 25%;&#34;&gt;
&lt;col style=&#34;width: 25%;&#34;&gt;
&lt;col style=&#34;width: 25%;&#34;&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;% бесперебойной работы&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;% недоступности&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Время простоя в год&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;&lt;strong&gt;Время простоя в неделю&lt;/strong&gt;&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;98%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;7.3 дня&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3 ч. 22 мин.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.65 дня&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1 ч. 41. мин&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.9%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;0.1%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;8 ч. и 45 мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;10 мин. 5 сек&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.99%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;0.01%&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;52.5 мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1 мин.&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;При эксплуатации системы и расчете доступности не всегда имеется в виду, что система эксплуатируется круглосуточно и весь год. Поэтому если кто-то декларирует доступность в несколько девяток следует уточнить в каких временных интервалах и как декларируют графики обслуживания системы для клиентов. Обычно в секции Service Level Agreement (SLA) оговаривается время когда именно эта сама доступность измеряется. Чаще всего используют привычные многим обозначения с &lt;code&gt;HxD&lt;/code&gt;, где &lt;code&gt;H&lt;/code&gt; - количество рабочих часов в сутках, &lt;code&gt;D&lt;/code&gt; - количество рабочих суток в неделе.
Типичные варианты:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;ulist&#34;&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;p&gt;24 x 7 - круглосуточно, опционально прописываются часы обслуживания  (maintenance window)&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;24 x 6 - 6 выбранных дней в неделю&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;14 x 5 - рабочие часы в будний день&lt;/p&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;Теперь сводная таблица:&lt;/p&gt;
&lt;/div&gt;
&lt;table class=&#34;tableblock frame-all grid-all stretch&#34;&gt;
&lt;caption class=&#34;title&#34;&gt;Table 3. SLA для различных тайм-фреймов доступности&lt;/caption&gt;
&lt;colgroup&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2857%;&#34;&gt;
&lt;col style=&#34;width: 14.2858%;&#34;&gt;
&lt;/colgroup&gt;
&lt;tbody&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-center valign-middle&#34; rowspan=&#34;2&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;SLA (%)&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-center valign-top&#34; colspan=&#34;2&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;24x7&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-center valign-top&#34; colspan=&#34;2&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;24x6&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-center valign-top&#34; colspan=&#34;2&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;14x5&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Месяц&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Год&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Месяц&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Год&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Месяц&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;Год&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;7.3ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.7д&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;6.3ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.1д&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.0ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.5д&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.5&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.7ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.8д&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.1ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.6д&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.5ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;18.3ч&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.8&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.5ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;17.5ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.3ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;15.0ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;36.6мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;7.3ч&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.9&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;43.8мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;8.8ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;37.6мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;7.5ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;18.3мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.7ч&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.99&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;4.4мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;52.6ч&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;3.8мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;45.1мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;1.8мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;21.9мин&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;tr&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;99.999&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;26.3сек&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;5.3мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;22.6сек&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;4.5мин&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;11.0сек&lt;/p&gt;&lt;/td&gt;
&lt;td class=&#34;tableblock halign-left valign-top&#34;&gt;&lt;p class=&#34;tableblock&#34;&gt;2.2мин&lt;/p&gt;&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;При таком подходе в оценке доступности системы необходимо отметить следующее:&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;olist arabic&#34;&gt;
&lt;ol class=&#34;arabic&#34;&gt;
&lt;li&gt;
&lt;p&gt;Относительно чего была замерена доступность, если доступ осуществляется через один из нестабильных маршрутов, то относительно его пользователей доступность будет ниже&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Выше приведенные “девятки” есть среднее значение, гораздо важнее видеть MTTR, хотя по маркетинговым соображениям его иногда и не публикуют.&lt;/p&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;p&gt;Иногда публикуют теоретические данные, основываясь на построенной модели, но важно вести замер фактической доступности и не забывать при этом про п1.&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;При обсуждении SLA имеет смысл обсуждать и фиксировать в договоренностях не абстрактные девятки процента доступности сервисов, а фактические (то есть абсолютные) показатели доступности сервисов в рабочие часы, чтобы избежать недопониманий и ложных ожиданий в будущем. Также не стоит недооценивать трудности достижения показателей высокой доступности таких как 99.99%, 53 минуты простоя в год должны означать, что организация имеет возможность обработать даже самый катастрофический сбой в системе менее чем за 1 час.&lt;/p&gt;
&lt;/div&gt;
&lt;div class=&#34;paragraph&#34;&gt;
&lt;p&gt;В следующей статье (Системы с высокой доступностью и аварийное восстановление. Вынужденные простои и сбои: причины, классификация, затраты.) будут рассмотрены основные причины сбоев, различные их классификаторы, ключевые этапы преодоления сбоя, его оценка.&lt;/p&gt;
&lt;/div&gt;
&lt;/div&gt;
&lt;/div&gt;
</description>
    </item>
    
  </channel>
</rss>
