<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Микросервисы | Alexander Salimonov</title>
    <link>/tags/%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D1%8B/</link>
      <atom:link href="/tags/%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D1%8B/index.xml" rel="self" type="application/rss+xml" />
    <description>Микросервисы</description>
    <generator>Source Themes Academic (https://sourcethemes.com/academic/)</generator><language>en-us</language><copyright>Alexander Salimonov · ©  2019</copyright><lastBuildDate>Mon, 20 Mar 2017 00:00:00 +0000</lastBuildDate>
    <image>
      <url>/img/avatar_salimonov_small.jpeg</url>
      <title>Микросервисы</title>
      <link>/tags/%D0%BC%D0%B8%D0%BA%D1%80%D0%BE%D1%81%D0%B5%D1%80%D0%B2%D0%B8%D1%81%D1%8B/</link>
    </image>
    
    <item>
      <title>Распределенные приложения: типичные проблемы и решения</title>
      <link>/post/2017/01-distsys/</link>
      <pubDate>Mon, 20 Mar 2017 00:00:00 +0000</pubDate>
      <guid>/post/2017/01-distsys/</guid>
      <description>&lt;p&gt;Небольшая заметка о построении распределённых приложений, как сохранять эффективность маленькой команды несмотря на рост сложности на проекте.&lt;/p&gt;
&lt;p&gt;Прежде всего хочется отметить, что перед стартом проекта важно обозначить архитектурные ограничения и обосновать их до начала этапа кодирования, что облегчит жизнь в будущем, так как архитектура проекта — это прежде всего ограничения, а не возможности, которые не дают приложению стать чрезмерно сложным и неконтролируемым. Таким образом, определяя основной набор ограничений, мы определяем варианты имплементации, делая код относительно шаблонным и предсказуемым, что важно для цены поддержки в будущем.&lt;/p&gt;
&lt;p&gt;Мотивация создания распределённого приложения:&lt;/p&gt;
&lt;ol&gt;
&lt;li&gt;модульность, некоторые части должны быть относительно автономны;&lt;/li&gt;
&lt;li&gt;безопасность, приложение должно взаимодействовать как с сервисами из Internet так и с внутренними корпоративными, в связи с чем некоторые его части могут находиться в различных сегментах сети, например в &lt;a href=&#34;https://ru.wikipedia.org/wiki/DMZ_(%D0%BA%D0%BE%D0%BC%D0%BF%D1%8C%D1%8E%D1%82%D0%B5%D1%80%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8)&#34;&gt;DMZ&lt;/a&gt;;&lt;/li&gt;
&lt;li&gt;максимально эффективная утилизация ресурсов оборудования из-за серьезных ограничений на цену транзакции, в противном случае создание и использование приложения может терять экономический смысл.&lt;/li&gt;
&lt;li&gt;требования определённого уровня отказоустойчивости.&lt;/li&gt;
&lt;/ol&gt;
&lt;p&gt;Теперь можно перейти к списку проблем, которые я постараюсь описать в порядке их возникновения и о том, как их можно преодолеть.&lt;/p&gt;
&lt;p&gt;Управление конфигурационными параметрами
&lt;strong&gt;П:&lt;/strong&gt; Каждый сервис обычно имеет некоторый набор конфигурационных параметров, настраивать каждый по отдельности нудно и требует много времени.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Р:&lt;/strong&gt; Использовать REST-сервис, который раздаёт конфигурационные параметры другим сервисам и оповещает об их изменении через Message Broker. Сервис-клиент при старте имеет лишь адрес сервиса конфигурации и bearer-токен, с помощью которого идентифицируется клиент и отдаются его параметры. В случае необходимости сервис подписывается на обновление конфигурационных параметров через MB.
Для облегчения тестирования и возможности использовать каждый сервис в автономном режиме имеет смысл использовать под одной абстракцией два типа клиента: для использования локальных конфигурационных параметров и для получения конфигурационных параметров с удалённого сервиса.&lt;/p&gt;
&lt;h3 id=&#34;heading&#34;&gt;Логирование&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;П:&lt;/strong&gt; Много сервисов — много логов и на разных серверах, также следует помнить, что интенсивное логирование может создать конкуренцию за ресурсы сервера.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Р:&lt;/strong&gt; Для логов следует организовывать два таргета: централизованный и локальный. В первом случае логи собираются и используются когда инфраструктура функционирует в штатном режиме, во втором - когда проблемы с сетью.&lt;/p&gt;
&lt;p&gt;В качестве примера предлагаю рассмотреть следующий вариант из собственной практики:
Так как сервисы уже использовали RabbitMQ, для получения нотификаций от других сервисов, было решено использовать его, дописав для него таргет для NLog. Таким образом, мы получаем логи в JSON-формате и отправляем через RabbitMQ. Основным потребителем логов является Logstash c плагином к RabbitMQ, который их индексирует и отправляет в Elasticsearch. Графически схему логирования можно представить следующим образом:













&lt;figure&gt;


  &lt;a data-fancybox=&#34;&#34; href=&#34;img01.png&#34; data-caption=&#34;Пример организации логирования в распределённом приложении&#34;&gt;
&lt;img src=&#34;img01.png&#34; alt=&#34;&#34; &gt;&lt;/a&gt;


  
  
  &lt;figcaption&gt;
    Пример организации логирования в распределённом приложении
  &lt;/figcaption&gt;


&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;Конечно можно было бы обойтись и без RabbitMQ, отправляя логи напрямую в Logstash, но это бы создало две следующие проблемы:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Конкуренция за ресурсы между сервисом и Logstash, а он очень прожорлив;&lt;/li&gt;
&lt;li&gt;Каждый environment приходилось настраивать с учётом необходимости дополнительно разворачивать Logstash и организовывать доступ к Elasticsearch&lt;/li&gt;
&lt;/ul&gt;
&lt;h3 id=&#34;heading-1&#34;&gt;Тестирование&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;П:&lt;/strong&gt; При работе со сложной предметной областью, большим количестве кейсов, когда спецификации для форматов и протоколов могут меняться независимыми от нас факторами, появляется очень болезненная проблема тестирования: удовлетворительное регрессионное тестирование превращается в нереальное требование, а юнит-тесты становятся очень дорогими.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Р:&lt;/strong&gt; В ситуациях когда невозможно зафиксировать требования и спецификации, юнит-тесты становятся очень хрупкими, а как следствие очень дорогими для бюджета, но при этом не решают проблему комплексно. В таких случаях стоит сфокусироваться на интеграционных тестах, когда можно тестом покрыть use case или вообще бизнес-процесс с конкретным business value, при этом не вдаваясь в детали реализации, (продаём не код, а решение). Решая эту проблему мы отчасти создаём себе две следующие.&lt;/p&gt;
&lt;h3 id=&#34;--&#34;&gt;Сборка и развёртывание&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;П:&lt;/strong&gt; Увеличение количества собираемых приложений, ресурсов, инсталляторов неминуемо влечёт увеличение времени на компиляцию, сборку, развёртывание и тестирование. Особенно если основная статья расходов — фонд заработной платы.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Р:&lt;/strong&gt; Билды не должны строиться долго, чтобы у инженера не было повода выходить из рабочего контекста. Если проекты становятся слишком большие, имеет смысл их дробить. Чем быстрее будет собран проект - тем быстрее его можно запустить и протестировать, тем больше эффективность инженеров и тестеров.
Разработчик должен иметь возможность запустить юнит и интеграционные тесты одной - двумя командами.
Continuos Integration и Continuous Delivery решения отличные помощники, но для автоматизации прежде всего стоит думать с позиции расходов времени персоналом и без создания отдельных environment для билд-сервера. Грубо говоря, приложение должно собираться тем же набором инструментов и на компьютере разработчика, и на билд-сервере.&lt;/p&gt;
&lt;p&gt;Избегайте мыслей: “Наймём DevOps инженера и сразу заживём хорошо!” Хорошо не заживёте, каждый инженер и тестер должен обладать знанием, что и как собирается, где взять различные версии билдов, где билд может быть развёрнут. Большим плюсом будет возможность разворачивать систему для Nighltly-билда автоматически, либо по потребности, чтобы для всех заинтересованных лиц на проекте была возможность видеть приложение в действии. Для того, чтобы не путаться в билдах имеет смысл использовать semantic versioning.&lt;/p&gt;
&lt;h3 id=&#34;---1&#34;&gt;Программно-аппаратное обеспечение&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;П:&lt;/strong&gt; Большие затраты времени на сборку, запуск, развёртывание, невозможно запустить все компоненты приложения, падение эффективности персонала.
&lt;strong&gt;Р:&lt;/strong&gt; Не стоит недооценивать значимость программно-аппаратного обеспечения для людей вовлеченных в разработку распределённых приложений. Прежде всего стоит разобраться с тем, какие есть текущие показатели (цифры), что даст апгрейд или дополнительное ПО и как это повлияет на экономические показатели проекта и удовлетворённость персонала. Когда час работы инженера стоит $10–20, а 500GB SSD и 32GB RAM стоят ~$450, которые могут увеличить его производительность хотя бы на 1/4, то подобное вложение может окупить себя уже через месяц - полтора, а потом увеличивать доход из-за сэкономленных человеко-часов. Хорошее вложение в 25% годовых, не правда ли?&lt;/p&gt;
&lt;h3 id=&#34;heading-2&#34;&gt;Мониторинг&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;П:&lt;/strong&gt; Отсутствие информации о состоянии приложения ведёт к недоступности информации для принятия обоснованных решений и фактической потерей контроля над ним.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Р:&lt;/strong&gt; Мониторинг состояния приложения является отличным элементом оперативного контроля и управления. Позволяет уменьшить время на выявление внештатных ситуаций, уменьшить затраты времени на их устранение, а также даёт возможность анализировать поведение программных агентов и пользователей. В качестве примера можно упомянуть Open Monitoring Distribution (OMD) со следующим набором инструментов: Icinga2, Thruk, Grafana, InfluxDB.&lt;/p&gt;
</description>
    </item>
    
  </channel>
</rss>
